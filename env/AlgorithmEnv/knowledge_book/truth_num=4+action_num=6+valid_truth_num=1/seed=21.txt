# Programming Analysis Guidebook

This guidebook introduces you to four key algorithms and outlines a series of experiments designed to analyze their operational characteristics. The objective is to utilize experimentation outcomes to rule out unsuitable algorithms for a given computational problem.

## Algorithms Overview

### 1. Breadth First Search (BFS)
Breadth First Search is a graph traversal algorithm often used for finding the shortest path in unweighted graphs. It explores all neighbor nodes at the present depth prior to moving on to nodes at the next depth level.

### 2. Binary Search
Binary Search is an efficient algorithm for finding an item from a sorted list of items, utilizing a divide-and-conquer strategy by repeatedly dividing the list in half. 

### 3. Hashing
Hashing is a technique for converting a range of key values into a range of indexes of an array. It is most commonly implemented in data structures like hash tables. However, its strength varies with different contexts (e.g., cryptography).

### 4. Quick Sort
Quick Sort is a highly efficient sorting algorithm and is based on partitioning an array into different segments. It sorts an array by selecting a 'pivot' element and dividing the other elements into two sub-arrays, according to whether they are less than or greater than the pivot.

## Experiments

### 1. Recursive Depth Analysis
This experiment measures the extent of recursive calls an algorithm can produce. Recursive depth can be indicative of the algorithm's stack usage and possible level of complexity in recursive solutions.

#### Exclusion Rules:
- For a recursive depth between 0 and 100: Rule out **Quick Sort**.
- For a recursive depth between 100 and 1000: Rule out **Breadth First Search**.
  
### 2. Worst Case Execution Time
This test evaluates algorithms under their worst-case input scenarios to determine their execution duration. It is essential for understanding resource limitations and potential performance bottlenecks.

#### Exclusion Rules:
- For a time between 0 and 10 units: Rule out **Quick Sort**.
- There are no additional exclusions for other ranges in worst-case scenarios.

### 3. Cryptographic Strength Test
This assesses the cryptographic security of algorithms, primarily focusing on hash functions and their ability to resist attacks.

#### Exclusion Rules:
- If an algorithm is found weak in cryptographic context, rule it out; here, **Hashing** is considered weak.

### 4. Disk I/O Measurement
This experiment evaluates how efficiently an algorithm performs with large input sizes that involve significant disk input/output operations.

#### Exclusion Rules:
- For disk I/O interactions between 100 and 1000 units: Rule out **Quick Sort**.

### 5. Algorithm Stability Test
Stability in an algorithm refers to its ability to maintain the relative order of equal elements after sorting.

#### Exclusion Rules:
- If the algorithm is stable, rule out **Quick Sort**.

### 6. Computational Complexity Class
This analysis classifies problems based on the complexity class they fall into, such as P (problems solvable in polynomial time) and NP (nondeterministic polynomial time).

#### Exclusion Rules:
- For NP class complexity problems, rule out **Quick Sort**, indicating challenges in efficiently solving some problems.

## Summary

This guidebook equips you with both the knowledge of foundational algorithms and the analytical framework to rigorously test these algorithms in practical settings. The outcome-based exclusion rules are crucial for narrowing down your problem-solving avenues, efficiently eliminating non-viable algorithms upon conducting relevant experiments. Use these guidelines to decide which algorithms should be excluded based on the observed outcomes of your experimentation.