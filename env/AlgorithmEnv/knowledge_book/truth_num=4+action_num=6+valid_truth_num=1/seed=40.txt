# Programming Analysis Guidebook

This guidebook serves as an introduction to several key algorithms and provides an overview of experiments designed to analyze their performance characteristics. For each experiment, we determine which algorithms should be excluded based on observed outcomes, helping practitioners to identify unsuitable algorithms for specific applications.

## Algorithms

1. **MapReduce**
   - **Description**: MapReduce is a programming model for processing and generating large data sets with a parallel, distributed algorithm on a cluster.
   - **Characteristics**: Highly scalable but may have overhead in smaller data contexts.
   
2. **Approximation Algorithms**
   - **Description**: These algorithms are used for problems where finding the exact solution is impractical. They provide solutions that are close to the optimal within a provable bound.
   - **Characteristics**: Efficient for complex, large-scale problems.
   
3. **Bubble Sort**
   - **Description**: A simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order.
   - **Characteristics**: Not efficient for large lists, with a typical time complexity of O(n²).
   
4. **Breadth First Search (BFS)**
   - **Description**: An algorithm for traversing or searching tree or graph data structures. It starts at the tree root (or an arbitrary node of a graph) and explores all neighbor nodes at the present depth prior to moving on to nodes at the next depth level.
   - **Characteristics**: Useful for finding the shortest path in unweighted graphs.

## Experiments and Analysis

### 1. Recursive Depth Analysis
- **Description**: Measures the impact of recursive function calls depth on performance.
- **Exclusion Rules**:
  - Depth range [0, 100]: No algorithms excluded.
  - Depth range [100, 1000]: Exclude 'Breadth First Search' due to its sensitivity to deep recursion.

### 2. Scalability Test
- **Description**: Assesses an algorithm's ability to handle increasing amounts of work or a larger dataset.
- **Exclusion Rules**:
  - Scales well: Exclude 'Bubble Sort' as it is not efficient in larger dataset contexts.
  - Does not scale well: Exclude 'MapReduce' as it exhibits overhead at smaller scales.

### 3. Overhead Measurement
- **Description**: Evaluates the resource overhead generated by an algorithm beyond the core logic time and memory.
- **Exclusion Rules**:
  - Overhead range [0, 10]: No algorithms excluded.
  - Overhead range [10, 100]: Exclude 'MapReduce' due to significant overhead in typical scenarios.

### 4. Time Complexity Analysis
- **Description**: Determines the relationship between the size of the input and time taken by the algorithm.
- **Exclusion Rules**:
  - O(n log n) or better: Exclude 'Bubble Sort' since it generally performs worse.
  - O(n²) or worse: All algorithms included.

### 5. Worst Case Execution Time
- **Description**: Focuses on the maximum time taken by the algorithm to complete under the most demanding circumstances.
- **Exclusion Rules**:
  - Execution time [0, 10]: No algorithms excluded.
  - Execution time [10, 1000]: Exclude 'Bubble Sort' as it may not handle worst-case scenarios quickly.

### 6. Memory Usage Profiling
- **Description**: Profiles an algorithm's memory usage, identifying potential inefficiencies.
- **Exclusion Rules**:
  - Memory range [0, 100]: Exclude 'MapReduce' due to high initial memory usage.
  - Memory ranges [100, 1000] and [1000, 10000]: No algorithms excluded.

By applying these tests and analyzing the outcomes based on exclusion rules, practitioners can identify which algorithms are unsuitable for given constraints and optimize their choice of algorithm accordingly.